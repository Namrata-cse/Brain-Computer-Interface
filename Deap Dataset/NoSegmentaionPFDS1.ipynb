{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: antropy in c:\\users\\namrata\\anaconda3\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: stochastic in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from antropy) (0.6.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from stochastic->antropy) (1.22.2)\n",
      "Requirement already satisfied: scipy<2.0,>=1.3 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from stochastic->antropy) (1.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "!pip install antropy\n",
    "import pickle, copy\n",
    "import numpy as np\n",
    "import antropy as ent\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, sosfilt, sosfreqz, freqz\n",
    "from sklearn.decomposition import FastICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_dataset_path = \"D:/Brain Computer interface/data_preprocessed_python/data_preprocessed_python/s01.dat\"\n",
    "subject_names = ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', 's11', 's12', \n",
    "                 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21',\n",
    "                 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30', 's31', 's32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (deap_dataset_path,'rb')as f:\n",
    "    raw_data=pickle.load(f , encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': array([[7.71, 7.6 , 6.9 , 7.83],\n",
      "       [8.1 , 7.31, 7.28, 8.47],\n",
      "       [8.58, 7.54, 9.  , 7.08],\n",
      "       [4.94, 6.01, 6.12, 8.06],\n",
      "       [6.96, 3.92, 7.19, 6.05],\n",
      "       [8.27, 3.92, 7.  , 8.03],\n",
      "       [7.44, 3.73, 7.08, 7.04],\n",
      "       [7.32, 2.55, 6.32, 5.87],\n",
      "       [4.04, 3.29, 3.62, 5.99],\n",
      "       [1.99, 4.86, 2.04, 7.09],\n",
      "       [2.99, 2.36, 3.63, 6.24],\n",
      "       [2.71, 2.77, 3.4 , 7.35],\n",
      "       [1.95, 3.12, 2.87, 6.18],\n",
      "       [4.18, 2.24, 3.04, 5.04],\n",
      "       [3.17, 8.08, 2.91, 5.04],\n",
      "       [6.81, 7.44, 8.15, 7.14],\n",
      "       [2.46, 6.91, 6.77, 6.41],\n",
      "       [7.23, 7.15, 6.94, 8.01],\n",
      "       [7.17, 8.  , 8.1 , 6.79],\n",
      "       [8.26, 7.91, 7.19, 8.13],\n",
      "       [9.  , 7.95, 8.37, 7.86],\n",
      "       [7.09, 2.08, 7.06, 7.37],\n",
      "       [8.15, 3.01, 7.37, 7.9 ],\n",
      "       [7.04, 7.09, 8.01, 8.22],\n",
      "       [8.86, 7.21, 8.65, 7.21],\n",
      "       [7.28, 7.27, 7.41, 8.24],\n",
      "       [7.35, 6.95, 7.03, 7.29],\n",
      "       [3.88, 3.35, 4.01, 7.87],\n",
      "       [1.36, 2.27, 3.  , 8.14],\n",
      "       [2.08, 2.99, 3.22, 7.33],\n",
      "       [3.03, 8.14, 2.86, 8.04],\n",
      "       [2.28, 8.  , 3.27, 3.95],\n",
      "       [3.81, 3.85, 4.78, 5.13],\n",
      "       [2.28, 7.09, 7.28, 6.92],\n",
      "       [2.06, 8.15, 8.05, 5.18],\n",
      "       [2.9 , 6.92, 6.5 , 3.87],\n",
      "       [2.31, 6.88, 3.1 , 6.77],\n",
      "       [3.33, 7.18, 6.54, 6.62],\n",
      "       [3.24, 6.18, 7.87, 6.15],\n",
      "       [5.1 , 7.12, 6.17, 5.97]]), 'data': array([[[ 9.48231681e-01,  1.65333533e+00,  3.01372577e+00, ...,\n",
      "         -2.82648937e+00, -4.47722969e+00, -3.67692812e+00],\n",
      "        [ 1.24706590e-01,  1.39008270e+00,  1.83509881e+00, ...,\n",
      "         -2.98702069e+00, -6.28780884e+00, -4.47429041e+00],\n",
      "        [-2.21651099e+00,  2.29201682e+00,  2.74636923e+00, ...,\n",
      "         -2.63707760e+00, -7.40651010e+00, -6.75590441e+00],\n",
      "        ...,\n",
      "        [ 2.30779684e+02,  6.96716323e+02,  1.19512165e+03, ...,\n",
      "          1.01080949e+03,  1.28312149e+03,  1.51996480e+03],\n",
      "        [-1.54180981e+03, -1.61798052e+03, -1.69268642e+03, ...,\n",
      "         -1.57842691e+04, -1.57823160e+04, -1.57808512e+04],\n",
      "        [ 6.39054310e-03,  6.39054310e-03,  6.39054310e-03, ...,\n",
      "         -9.76081241e-02, -9.76081241e-02, -9.76081241e-02]],\n",
      "\n",
      "       [[ 1.02601750e+01,  1.27954427e+01,  1.04261916e+01, ...,\n",
      "          6.02219406e+00,  7.53913583e+00,  9.35224904e+00],\n",
      "        [ 9.49186875e+00,  1.25897704e+01,  1.05740268e+01, ...,\n",
      "          6.03399490e+00,  9.06874552e+00,  8.74021419e+00],\n",
      "        [ 7.12867480e+00,  1.22064700e+01,  9.49646701e+00, ...,\n",
      "          6.17971667e+00,  6.93374514e+00,  6.48086477e+00],\n",
      "        ...,\n",
      "        [ 1.91950410e+03,  3.51250116e+03,  3.67262586e+03, ...,\n",
      "         -1.62148301e+02, -3.66241674e+02, -4.51866515e+02],\n",
      "        [-7.42916132e+03, -7.50972650e+03, -7.57076073e+03, ...,\n",
      "         -5.49462041e+03, -5.59081036e+03, -5.69139477e+03],\n",
      "        [ 5.98429831e-03,  5.98429831e-03,  5.98429831e-03, ...,\n",
      "         -6.20148303e-02, -6.20148303e-02, -6.20148303e-02]],\n",
      "\n",
      "       [[ 1.01304956e+00, -1.06783230e+00,  3.90824949e+00, ...,\n",
      "          2.18687657e+00,  2.66767712e-02, -7.51193325e+00],\n",
      "        [ 3.31725539e-02, -1.51860504e+00,  4.81957628e+00, ...,\n",
      "          3.98227619e-01, -1.06766739e+00, -5.90302866e+00],\n",
      "        [ 7.22816236e-01,  5.12160665e-01,  8.04440282e+00, ...,\n",
      "          9.66963103e-02,  2.20454025e-01, -4.36041903e+00],\n",
      "        ...,\n",
      "        [-2.14800222e+01, -2.61792078e+02, -1.01386125e+02, ...,\n",
      "          2.58992140e+03,  1.61176696e+03,  7.66674772e+02],\n",
      "        [ 1.16210735e+04,  1.14355295e+04,  1.12646336e+04, ...,\n",
      "          2.76134490e+03,  2.67687353e+03,  2.60314418e+03],\n",
      "        [ 2.90621276e-03,  2.90621276e-03,  2.90621276e-03, ...,\n",
      "         -1.51091814e-01, -1.51091814e-01, -1.51091814e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.13944132e+01, -1.34502274e+01, -9.66299865e+00, ...,\n",
      "         -2.43900889e+00, -2.33095827e+00, -3.36814485e+00],\n",
      "        [-9.19759768e+00, -1.04656392e+01, -6.56847604e+00, ...,\n",
      "         -3.51219647e+00, -2.91042815e+00, -2.82260677e+00],\n",
      "        [-8.61617511e+00, -1.00405069e+01, -6.40832041e+00, ...,\n",
      "         -4.15937090e+00, -4.30358260e+00, -2.69228055e+00],\n",
      "        ...,\n",
      "        [ 1.33536977e+03,  1.18468254e+03,  9.23995526e+02, ...,\n",
      "          9.61057957e+02,  5.48652469e+02,  1.16462008e+03],\n",
      "        [-3.84721885e+03, -3.90385861e+03, -3.96391629e+03, ...,\n",
      "          2.21035586e+04,  2.19683067e+04,  2.18359845e+04],\n",
      "        [ 1.74997757e-03,  1.74997757e-03,  1.74997757e-03, ...,\n",
      "          4.67494009e-02,  4.67494009e-02,  4.67494009e-02]],\n",
      "\n",
      "       [[ 2.53187763e+00,  1.58111089e-01, -4.67449746e+00, ...,\n",
      "          3.13209243e+00,  4.65647663e-01,  1.85004049e+00],\n",
      "        [ 6.21303506e+00,  1.60022210e+00, -4.68115214e+00, ...,\n",
      "          3.09468204e+00, -4.47081977e-01,  7.07338119e-01],\n",
      "        [ 7.13694330e+00,  4.83688756e+00, -2.90448250e+00, ...,\n",
      "          8.47561300e-02, -7.15406930e-02, -8.34269599e-01],\n",
      "        ...,\n",
      "        [-1.72646702e+03, -1.77037319e+03, -1.74206075e+03, ...,\n",
      "         -1.37621767e+03, -1.46368626e+03, -1.39456139e+03],\n",
      "        [ 7.78738138e+03,  7.87087621e+03,  7.88894234e+03, ...,\n",
      "          1.77575401e+03,  1.77087127e+03,  1.76891817e+03],\n",
      "        [ 1.30206665e-03,  2.30205383e-03,  2.30205383e-03, ...,\n",
      "         -1.06977796e-02, -1.06977796e-02, -1.06977796e-02]],\n",
      "\n",
      "       [[ 3.08300605e+00,  6.27214597e-01, -3.40256017e+00, ...,\n",
      "         -4.43802092e+00, -3.27103236e+00,  2.13500861e+00],\n",
      "        [-2.73052705e-01, -2.20023500e-01, -3.81054293e+00, ...,\n",
      "         -3.75791147e+00, -3.31224301e+00,  1.15426073e+00],\n",
      "        [-1.72910530e+00,  1.73630179e+00, -1.14991197e-01, ...,\n",
      "         -2.94468621e+00, -5.71142735e+00, -1.69792350e+00],\n",
      "        ...,\n",
      "        [-1.17067329e+02,  2.14775808e+02,  6.61994220e+00, ...,\n",
      "         -1.10328426e+03, -1.11556548e+03, -1.07090932e+03],\n",
      "        [-7.16243920e+03, -7.22005551e+03, -7.17659914e+03, ...,\n",
      "          4.80999311e+02,  3.31587520e+02,  1.82175728e+02],\n",
      "        [ 4.24473727e-04,  4.24473727e-04,  4.24473727e-04, ...,\n",
      "          1.86422090e-01,  1.86422090e-01,  1.86422090e-01]]])}\n"
     ]
    }
   ],
   "source": [
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 8064)\n"
     ]
    }
   ],
   "source": [
    "data=raw_data['data']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n",
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 32, 7680)\n",
      "[[[ 7.95648528e-01  2.89501356e+00  2.61935760e+00 ...  1.39535332e+00\n",
      "   -3.99159442e+00 -5.33963190e+00]\n",
      "  [ 5.99469265e-01  2.56429761e+00  3.35377849e+00 ...  3.13934281e+00\n",
      "   -4.01302308e+00 -7.55416031e+00]\n",
      "  [ 2.32549631e-01  1.58746963e+00  3.19184223e+00 ...  3.15431765e+00\n",
      "   -4.35828486e+00 -8.80256423e+00]\n",
      "  ...\n",
      "  [ 5.38170240e-01  2.19210252e+00  3.58815943e+00 ...  2.77831240e+00\n",
      "    7.62529741e+00  7.26733037e+00]\n",
      "  [ 5.52265355e-01  2.24286773e+00  3.78882258e+00 ... -1.94641285e+00\n",
      "    3.79207073e+00  7.29873267e+00]\n",
      "  [ 7.19570848e-01  3.02262303e+00  4.84982576e+00 ... -1.53293283e+00\n",
      "    3.46835442e+00  3.81903014e+00]]\n",
      "\n",
      " [[-8.88176185e-01 -4.95794362e+00 -1.08714171e+01 ...  3.54493852e+00\n",
      "    8.13599910e+00  8.80617996e+00]\n",
      "  [-1.24602436e-01 -1.28229620e+00 -4.31482625e+00 ...  4.09423238e+00\n",
      "    7.43010495e+00  9.32669398e+00]\n",
      "  [ 2.89096823e-01  5.01637472e-01 -1.52059829e+00 ...  4.51104536e+00\n",
      "    7.50199258e+00  7.39482773e+00]\n",
      "  ...\n",
      "  [ 5.55133036e-01  2.31396661e+00  4.04759845e+00 ...  3.01578755e-01\n",
      "   -1.62942297e+00  2.18471910e-01]\n",
      "  [-4.46262033e-01 -1.09192152e+00  1.01075961e+00 ...  3.16788338e-02\n",
      "   -6.40617911e+00 -1.02001412e+01]\n",
      "  [-7.11053581e-02  7.32993959e-01  4.27759995e+00 ...  1.47149985e+00\n",
      "   -3.95870724e+00 -7.41675373e+00]]\n",
      "\n",
      " [[-2.96784316e-01 -2.14905693e-01  2.47327829e+00 ...  4.15073831e+00\n",
      "    2.52150209e-02 -2.77493066e+00]\n",
      "  [-2.40650274e-01  6.71000290e-02  3.05084454e+00 ...  2.88273757e+00\n",
      "   -7.21795353e-01 -3.63007808e+00]\n",
      "  [ 4.80269913e-01  2.42533944e+00  5.18563922e+00 ...  1.11801197e+00\n",
      "   -7.57386588e-01 -1.91287958e+00]\n",
      "  ...\n",
      "  [-2.05678537e+00 -7.96650455e+00 -1.06222838e+01 ...  7.29953317e-01\n",
      "    3.73816677e+00  1.65137802e+00]\n",
      "  [-1.33060508e+00 -5.68494505e+00 -9.24063874e+00 ... -8.82285611e-01\n",
      "    1.02542049e+00  5.04191558e+00]\n",
      "  [-1.92255548e+00 -7.88621569e+00 -1.19198055e+01 ...  2.06323457e+00\n",
      "    6.53925159e+00  8.68652354e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 6.16925983e-01  1.96192152e+00  1.89594716e+00 ... -2.47892225e+00\n",
      "   -3.45968776e+00 -1.52648586e+00]\n",
      "  [ 1.88193078e-01  9.20476214e-01  1.85433072e+00 ... -3.15085076e+00\n",
      "   -4.14932877e+00 -1.94315392e+00]\n",
      "  [ 5.34244224e-01  2.09299084e+00  2.52078864e+00 ... -2.85599452e+00\n",
      "   -4.40596060e+00 -2.58720358e+00]\n",
      "  ...\n",
      "  [ 3.67703998e-01  9.70268511e-01 -1.56643006e-01 ...  3.00909857e+00\n",
      "    2.26368701e-01  1.49723721e+00]\n",
      "  [-6.09712564e-01 -2.79283704e+00 -5.72490161e+00 ...  2.19329169e+00\n",
      "    1.09603661e+00 -2.46291816e+00]\n",
      "  [-8.60123876e-01 -3.70563598e+00 -6.85416824e+00 ...  2.45191519e+00\n",
      "    2.39330344e+00 -1.63404326e+00]]\n",
      "\n",
      " [[ 1.52221169e+00  5.90222477e+00  7.89362102e+00 ...  4.90072976e+00\n",
      "    2.07822506e+00 -1.14013054e+00]\n",
      "  [ 1.78558402e+00  7.03741728e+00  9.54683076e+00 ...  4.85355893e+00\n",
      "    2.90556570e+00 -1.07936698e+00]\n",
      "  [ 1.70274042e+00  6.55350182e+00  9.04807180e+00 ...  1.83286236e+00\n",
      "   -6.48589735e-02 -1.56165645e+00]\n",
      "  ...\n",
      "  [ 4.85171243e-01  5.91126671e-02 -5.75962805e+00 ...  1.94058176e+00\n",
      "    8.07787861e+00  5.82115313e+00]\n",
      "  [-1.11941089e+00 -5.77520192e+00 -1.30125275e+01 ... -2.06361097e+00\n",
      "    3.52952328e+00  5.52757981e+00]\n",
      "  [-7.12945820e-01 -3.87510947e+00 -9.02516161e+00 ... -1.91225401e+00\n",
      "    2.89696164e+00  5.66343494e+00]]\n",
      "\n",
      " [[-3.61436576e-02 -4.01027609e-01 -9.16644171e-01 ... -2.90151750e+00\n",
      "   -3.74968352e+00 -2.52382840e+00]\n",
      "  [ 2.04665816e-01  6.10422129e-01  3.54623762e-01 ... -1.22047166e+00\n",
      "   -3.18829570e+00 -2.98946367e+00]\n",
      "  [-2.35619142e-03 -2.14149966e-01 -5.65812717e-01 ... -8.86466735e-01\n",
      "   -3.33490073e+00 -4.49919406e+00]\n",
      "  ...\n",
      "  [-2.83727517e-01 -6.30654431e-01  6.31033378e-01 ... -1.41777723e+00\n",
      "    1.76090417e+00  3.46352100e-01]\n",
      "  [ 4.97475169e-02  4.85831102e-01  1.04419059e+00 ...  1.23347680e+00\n",
      "    3.00263888e+00  1.90108295e+00]\n",
      "  [-4.35047913e-01 -1.41548555e+00 -1.59920626e+00 ... -2.47194997e-01\n",
      "    1.75919820e+00  2.45025509e+00]]]\n"
     ]
    }
   ],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order = 3):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', analog=False)\n",
    "    return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order = 5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order = order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "def eye_movement_artifact(shyam): # parameter must be an 2D array like 32_channels*7860_data\n",
    "    # Inverse that 2D array\n",
    "    shyam = shyam.transpose()\n",
    "    ica = FastICA(n_components = 32, random_state = 0, tol = 0.05)\n",
    "    comps = ica.fit_transform(shyam)\n",
    "    # invert the array \n",
    "    data_after = comps.transpose()\n",
    "    return data_after\n",
    "def signal_pro(data):\n",
    "    fs=128                \n",
    "    lowcut=0.5\n",
    "    highcut=45\n",
    "    # do the bandpass filter\n",
    "    for i in range(40):\n",
    "        for j in range(32):\n",
    "            data[i][j] = butter_bandpass_filter(data[i][j], lowcut, highcut, fs, order=5)\n",
    "    # creating dummy variable which contains same data information \n",
    "    error_eye =  np.zeros((40,32,7680))\n",
    "    new_data =  np.zeros((40,32,7680))\n",
    "    for i in range(40):\n",
    "        for j in range(32):\n",
    "            for k in range(7680):\n",
    "                #print(data[i][j][k])\n",
    "                error_eye[i][j][k] = data[i][j][k]\n",
    "                new_data[i][j][k] = data[i][j][k]\n",
    "    for i in range(40):\n",
    "        error_eye[i] = eye_movement_artifact(error_eye[i])\n",
    "    for i in range(40):\n",
    "        for j in range(32):\n",
    "            mean_value = np.mean(data[i][j])\n",
    "            for k in range(7680):\n",
    "                if(data[i][j][k]>0.0): # data is positive\n",
    "                    if(mean_value>0.0): # error is positive\n",
    "                        new_data[i][j][k] = data[i][j][k] - mean_value\n",
    "                    elif(mean_value<0.0): # error is negative\n",
    "                        new_data[i][j][k] = data[i][j][k] - abs(mean_value)\n",
    "                elif(data[i][j][k]<0.0): # data is negative\n",
    "                    if(mean_value>0.0): # error is positive\n",
    "                        new_data[i][j][k] = data[i][j][k] + mean_value\n",
    "                    elif(mean_value<0.0): # error is negative\n",
    "                        new_data[i][j][k] = data[i][j][k] - mean_value\n",
    "    return new_data\n",
    "\n",
    "deap = \"D:/Brain Computer interface/data_preprocessed_python/data_preprocessed_python/s01.dat\"\n",
    "x = pickle.load(open(deap, \"rb\"), encoding=\"latin1\")    \n",
    "labels = x['labels']\n",
    "data = x['data']\n",
    "data = data[0:40 , 0:32 , 384:8064]\n",
    "filter_data = signal_pro(data)\n",
    "print(np.shape(filter_data))\n",
    "print(filter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 32, 7680)\n"
     ]
    }
   ],
   "source": [
    "print(filter_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 32, 7680)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for subject in subject_names:\n",
    "    \n",
    "    data = raw_data['data']\n",
    "    labels = raw_data['labels']\n",
    "    # we are excluding 3s pre base line i.e. first 3*128 = 384 data points from time series data\n",
    "    filter_data  = data[0:40, 0:32, 384:8064]\n",
    "    break\n",
    "\n",
    "filter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def petrosian_fd(data, axis=-1):\n",
    "    # Petrosian fractal dimension\n",
    "    \n",
    "    x = np.asarray(data)\n",
    "    N = x.shape[axis]\n",
    "    nzc_deriv = ent.num_zerocross(np.diff(x, axis=axis), axis=axis) # Number of sign changes in the first derivative of the signal\n",
    "    pfd = np.log10(N) / (np.log10(N) + np.log10(N / (N + 0.4 * nzc_deriv)))\n",
    "    return pfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window = 1 # fix window size\n",
    "pfd_features = []\n",
    "for video_no in range(0, 40):\n",
    "    for channel_no in range(0, 32):\n",
    "        input_data = filter_data[video_no][channel_no]\n",
    "        no_data_in_each_window = int(input_data.shape[0])\n",
    "        for i in range(window):\n",
    "            pfd = petrosian_fd(input_data)\n",
    "            pfd_features.append(pfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pfd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0154149030532622, 1.0152103914371116, 1.0153362779414403, 1.0157499052047951, 1.0163031035941392, 1.015938013867616, 1.0163603937865302, 1.0187111138570109, 1.0158910089248119, 1.015136908506288, 1.0154463414915795, 1.0174809403497347, 1.015462058225284, 1.0174395878929214, 1.0155982005752007, 1.0144844721371493, 1.015556323856845, 1.0164853143765953, 1.0149162420007065, 1.0150528836143955, 1.0155772636857454, 1.0159641213302237, 1.0154411022121796, 1.0157708178805673, 1.0158335383284438, 1.0172119450447301, 1.0155615590896958, 1.0150633893178453, 1.0161884572545297, 1.0171238993419238, 1.0146109735015392, 1.014273397202759, 1.0160528525670043, 1.0149898338299532, 1.0149582989269696, 1.0187316169785994, 1.0164176620202396, 1.0154987241629776, 1.0160580704096362, 1.018700861246632, 1.0160319793728054, 1.0151998960938364, 1.0151998960938364, 1.0167763903904161, 1.0142469917612325, 1.0155929666283572, 1.0147110442107723, 1.014236428271601, 1.0154987241629776, 1.015979783616402, 1.0142417101102195, 1.0149162420007065, 1.0162093085896804, 1.015467296768404, 1.0145161075620397, 1.0151894000113402, 1.0152681026169887, 1.0167036744957567, 1.0160371979449354, 1.0147794749015833, 1.0158753373204168, 1.0175222813936207, 1.0146899822834188, 1.0145951667107695, 1.0155406170555783, 1.0149530424606212, 1.0150686418917607, 1.0181307408656162, 1.0164072512465143, 1.0152576113372542, 1.0155929666283572, 1.0188596981283533, 1.0159014557469765, 1.0151001534468818, 1.0147373674299507, 1.017170518223954, 1.0134898034443471, 1.0145266512091153, 1.014695248044653, 1.0140778857991803, 1.0149950889980752, 1.015524908599924, 1.0141994501470084, 1.0144000781021125, 1.0157133009676789, 1.014874173194172, 1.014579358240897, 1.0153415209058696, 1.0150161078167188, 1.0166049320426864, 1.0157080710577713, 1.0151211574482026, 1.0152471193189676, 1.0169839555021092, 1.0143314726757844, 1.0146794502020666, 1.0154882491007136, 1.0151631565702104, 1.0153729748206732, 1.016386427522821, 1.0164592978637537, 1.0159066788838742, 1.0162301570143324, 1.0195647489355832, 1.0157028409645243, 1.0151946481449985, 1.0151894000113402, 1.0163603937865302, 1.014763685995354, 1.0163656008966826, 1.0149109840497528, 1.014157178169068, 1.0152366265620072, 1.0160215416812954, 1.014114894168415, 1.014695248044653, 1.0160163225618857, 1.015451580586887, 1.0146531167378112, 1.0155824981836445, 1.0154882491007136, 1.0177184957202619, 1.0154882491007136, 1.0152995720260938, 1.016068505547904, 1.0159275696039156, 1.014695248044653, 1.0142892382174047, 1.0156609936165335, 1.015420143253352, 1.015556323856845, 1.0164488899903472, 1.0169320912180686, 1.0161728168425805, 1.0163760145726164, 1.0201650096098627, 1.015990224227692, 1.0154096626689892, 1.0155406170555783, 1.0172430076386552, 1.014273397202759, 1.0161519604117715, 1.0148636541353269, 1.0145161075620397, 1.0155091984894753, 1.0160841568880365, 1.0146794502020666, 1.0151946481449985, 1.0164228671351236, 1.0160163225618857, 1.0152943275859563, 1.016000664108858, 1.01604763454202, 1.018562382460933, 1.017092812018318, 1.0153886992897612, 1.0161258857765854, 1.0177339753881898, 1.0146478494858298, 1.014273397202759, 1.016204096028789, 1.0151998960938364, 1.0152943275859563, 1.0161415311040094, 1.017118718569717, 1.0160580704096362, 1.0169839555021092, 1.0191206456562119, 1.0170461689216928, 1.015619134526175, 1.0159327918271133, 1.017020249806954, 1.0145371941091195, 1.01604763454202, 1.0155353810875347, 1.0142311462453613, 1.0157655899864004, 1.0166309232220854, 1.0146636506825977, 1.0152628570694329, 1.015943235725438, 1.0164488899903472, 1.0152313799064865, 1.0157812731194387, 1.0163603937865302, 1.018516194473302, 1.0160998065878042, 1.0149635552078113, 1.0162874751826156, 1.017532614872185, 1.0150738942804902, 1.0148636541353269, 1.015430623101042, 1.0152471193189676, 1.0152366265620072, 1.0159014557469765, 1.0170617182359196, 1.0157185306942622, 1.0158335383284438, 1.0198855247550984, 1.0160215416812954, 1.014621510429423, 1.0152156388315794, 1.017862910489077, 1.0147057790083143, 1.0169528390892117, 1.0151789031895015, 1.0143895254805257, 1.0156243675548937, 1.0159641213302237, 1.0146478494858298, 1.0150266161139476, 1.0158596640702853, 1.0156296004000327, 1.014695248044653, 1.0155877324978435, 1.0154568194981166, 1.0173361567709598, 1.0155510884402184, 1.015010853390104, 1.0156139013138612, 1.0163812211384273, 1.0141730315692783, 1.0140673102868314, 1.0162666347569413, 1.0146425820474356, 1.0148320924995218, 1.0157133009676789, 1.0157342187742175, 1.015283838152071, 1.0158596640702853, 1.018844334154358, 1.015958900202973, 1.014805786024943, 1.0151736545012908, 1.0171031751770085, 1.0135269585932936, 1.0146373144226133, 1.0151998960938364, 1.0137655913776331, 1.0153048162817147, 1.0157655899864004, 1.0135057282183126, 1.0150003439807975, 1.0167348427803895, 1.0156505299450918, 1.0140937476570744, 1.014874173194172, 1.0151894000113402, 1.0166465157610807, 1.015896232427294, 1.0148215704674213, 1.015493486723824, 1.017697853675617, 1.0146004358275726, 1.0155353810875347, 1.0160163225618857, 1.0148952090829633, 1.0148952090829633, 1.0156086679179377, 1.0164592978637537, 1.0153729748206732, 1.0164488899903472, 1.0196106159228069, 1.0169891409418335, 1.014984578476416, 1.0153415209058696, 1.0178989924537833, 1.0137602925905171, 1.0153939404109187, 1.0151684056281989, 1.0140408682135793, 1.015147408286714, 1.015911901838002, 1.0136171538331766, 1.0143948018848965, 1.0172585365190496, 1.0154777733025626, 1.0135587984643113, 1.0152943275859563, 1.015273347979937, 1.0179917347977354, 1.0169113404691343, 1.015273347979937, 1.0157551336485293, 1.0192483958596168, 1.0144844721371493, 1.0149688113031616, 1.0161884572545297, 1.0153310347926006, 1.0154463414915795, 1.016558136529142, 1.0171342603483804, 1.0161571747925409, 1.0165113263613752, 1.0200786787296294, 1.0165113263613752, 1.0150843985024522, 1.0159066788838742, 1.0161206703031762, 1.0142892382174047, 1.0160841568880365, 1.016136316176987, 1.014415905630986, 1.0158439891740134, 1.0171964113304177, 1.0144581041436982, 1.0156557618725575, 1.015896232427294, 1.015938013867616, 1.0151316583386012, 1.015786500464173, 1.015917124609375, 1.018480260657021, 1.0156296004000327, 1.0151841516928464, 1.0163916337258116, 1.0170772659346639, 1.0155196720803275, 1.0166465157610807, 1.0152995720260938, 1.0150476304848304, 1.0151106558176701, 1.0188340906321625, 1.0166101306400754, 1.0153362779414403, 1.0155039614181895, 1.0188699399049805, 1.0152943275859563, 1.0153415209058696, 1.0150528836143955, 1.0167036744957567, 1.0144000781021125, 1.0164853143765953, 1.0151736545012908, 1.0147952621335605, 1.0150896503357154, 1.0153048162817147, 1.0142522732246555, 1.014558277668409, 1.016204096028789, 1.0162301570143324, 1.0150318699845924, 1.0158283126311973, 1.0172740637889197, 1.0178835298179147, 1.0164801114363309, 1.0158439891740134, 1.0155301449356549, 1.0175016122978333, 1.014415905630986, 1.0146583838033953, 1.015010853390104, 1.0145002906903975, 1.0145319227524936, 1.0148794324449593, 1.015289082961287, 1.0152785931582926, 1.0154149030532622, 1.018654715837395, 1.0153205479416294, 1.0147215740570197, 1.0147952621335605, 1.0170876301698635, 1.0139403454092917, 1.016370807825373, 1.0148583943272382, 1.01333577581466, 1.0153415209058696, 1.0158230867509566, 1.0136012410069422, 1.0147426315152719, 1.015958900202973, 1.0150949019838533, 1.0140778857991803, 1.0153362779414403, 1.0150161078167188, 1.0163447713671536, 1.0152576113372542, 1.0141518933266422, 1.0150266161139476, 1.016854261063336, 1.0137496944491777, 1.013633064954301, 1.016454094017656, 1.0152366265620072, 1.0154463414915795, 1.0171238993419238, 1.016454094017656, 1.0164228671351236, 1.0163031035941392, 1.0194984719316205, 1.0168490709462525, 1.015010853390104, 1.0160893736368688, 1.0177804048018042, 1.0141254662961443, 1.0163760145726164, 1.0154987241629776, 1.0142469917612325, 1.0160528525670043, 1.0166049320426864, 1.0144264563814116, 1.0156662251770354, 1.0158021813997513, 1.0156296004000327, 1.0148899503893396, 1.0159484574005953, 1.0161311010678507, 1.017651398676891, 1.0164384813920382, 1.0152471193189676, 1.0165633367541163, 1.0181358867653778, 1.0151526578994832, 1.0146478494858298, 1.017092812018318, 1.0153782164946534, 1.0151054047248156, 1.0158753373204168, 1.0160841568880365, 1.016073722843569, 1.0165633367541163, 1.0191921991411124, 1.016714064645832, 1.0155510884402184, 1.015943235725438, 1.0169372784556108, 1.0142997979564818, 1.0165477355364303, 1.0147373674299507, 1.0139509299596814, 1.0165217298878426, 1.0168075435249222, 1.0133198327942758, 1.0156452978341215, 1.0179968854687504, 1.0168438806490736, 1.0142205816299565, 1.015462058225284, 1.0159850040133198, 1.0171653390651394, 1.015995444259533, 1.0148794324449593, 1.0167296485174127, 1.017873220507974, 1.0147689491501508, 1.0136966923962334, 1.015619134526175, 1.01515790732731, 1.015430623101042, 1.0158648886698802, 1.0164072512465143, 1.0159745630369232, 1.01652693137954, 1.0194372672378234, 1.0154987241629776, 1.0148794324449593, 1.0158335383284438, 1.0151894000113402, 1.0132454093744632, 1.014452829984163, 1.0151894000113402, 1.0142417101102195, 1.0157133009676789, 1.016261424196202, 1.0145266512091153, 1.0153991813478327, 1.0156505299450918, 1.0153991813478327, 1.0147689491501508, 1.0154358627486721, 1.0159484574005953, 1.0177752466882426, 1.0156505299450918, 1.015273347979937, 1.0168905868414762, 1.0163760145726164, 1.015220886041288, 1.0157133009676789, 1.0165685367981887, 1.0157446765778417, 1.0159745630369232, 1.0172171225913267, 1.0169217162033837, 1.0164957197137716, 1.0170824481419838, 1.0199770496169196, 1.017206767319056, 1.0153991813478327, 1.0166932836236608, 1.0186752266584993, 1.0152995720260938, 1.0173930527278177, 1.0158596640702853, 1.0146847163358952, 1.0161676030079305, 1.0170254339890725, 1.014763685995354, 1.0159484574005953, 1.0162301570143324, 1.0160319793728054, 1.015566794138786, 1.015619134526175, 1.0164176620202396, 1.0181050087185923, 1.0168438806490736, 1.0153834579843444, 1.0171342603483804, 1.0186854810187682, 1.0154882491007136, 1.0151054047248156, 1.015870113086586, 1.015430623101042, 1.015687149584598, 1.015995444259533, 1.01700988090386, 1.0166776959614723, 1.016750424486876, 1.0196870298546832, 1.0156452978341215, 1.0148583943272382, 1.0162770553332052, 1.0146478494858298, 1.0138715274477732, 1.0145740883777337, 1.014236428271601, 1.0141994501470084, 1.0157603619090596, 1.0171031751770085, 1.0145371941091195, 1.0155301449356549, 1.0158021813997513, 1.0154777733025626, 1.0149530424606212, 1.0157185306942622, 1.0157080710577713, 1.0178577552137344, 1.0150055987781355, 1.0151001534468818, 1.017408566056146, 1.0155353810875347, 1.015493486723824, 1.0142047332993018, 1.0158857852395147, 1.0153467636859035, 1.015283838152071, 1.0169217162033837, 1.0164280720687082, 1.0158126344414322, 1.015922347198008, 1.0194627722192764, 1.0157655899864004, 1.015451580586887, 1.015430623101042, 1.0157342187742175, 1.0145319227524936, 1.0158230867509566, 1.015147408286714, 1.0150318699845924, 1.0156452978341215, 1.0159014557469765, 1.0147899999089038, 1.015021362057995, 1.016386427522821, 1.0158387638427107, 1.0150738942804902, 1.0157969546043144, 1.0156923802279527, 1.0181204485364923, 1.01604763454202, 1.0153939404109187, 1.015420143253352, 1.0169943262018561, 1.0147373674299507, 1.0145266512091153, 1.0153205479416294, 1.0147531591275227, 1.014763685995354, 1.0185059285462201, 1.0160893736368688, 1.0153310347926006, 1.0157133009676789, 1.0183980939071535, 1.0149950889980752, 1.014489745175103, 1.0146478494858298, 1.0154149030532622, 1.0136436714213117, 1.0149950889980752, 1.014921499766031, 1.0139668053718187, 1.0154987241629776, 1.015938013867616, 1.0145530070586377, 1.014579358240897, 1.0156923802279527, 1.0151211574482026, 1.0145951667107695, 1.0153362779414403, 1.014921499766031, 1.015493486723824, 1.0149477858087508, 1.0150528836143955, 1.0155772636857454, 1.016667303283812, 1.014563548091505, 1.0149950889980752, 1.0161936703612284, 1.015524908599924, 1.0159536788931018, 1.0190234828527123, 1.0179762817231632, 1.0166724997129388, 1.017092812018318, 1.0195953284801447, 1.0167452307651066, 1.0157499052047951, 1.0161832439658653, 1.0166413184287684, 1.014579358240897, 1.015786500464173, 1.0148320924995218, 1.0148110476917, 1.015911901838002, 1.017315461971199, 1.014800524172235, 1.0155353810875347, 1.0161206703031762, 1.0159850040133198, 1.0153572486928457, 1.01604763454202, 1.0164801114363309, 1.0175894362672697, 1.016105022789937, 1.0157133009676789, 1.0170617182359196, 1.018516194473302, 1.0151054047248156, 1.014579358240897, 1.015911901838002, 1.0148583943272382, 1.0152313799064865, 1.0173723657899745, 1.0174344180329815, 1.016000664108858, 1.0166776959614723, 1.0196360915438991, 1.0166205272925604, 1.0155877324978435, 1.0155615590896958, 1.0171653390651394, 1.0146689173754333, 1.0159066788838742, 1.0149109840497528, 1.0146899822834188, 1.0151316583386012, 1.0161884572545297, 1.0144106299751419, 1.0150423771700186, 1.0158387638427107, 1.0154777733025626, 1.0146531167378112, 1.0153572486928457, 1.0154568194981166, 1.018048382451878, 1.016261424196202, 1.0154463414915795, 1.0158439891740134, 1.0174861086042137, 1.0147110442107723, 1.0145846279174473, 1.0161467458489326, 1.014984578476416, 1.0154882491007136, 1.0157812731194387, 1.0165321326902326, 1.0155039614181895, 1.016068505547904, 1.0196411861507386, 1.0156139013138612, 1.0152366265620072, 1.015352006281557, 1.0157028409645243, 1.0133145180734788, 1.014874173194172, 1.015430623101042, 1.0138979996666315, 1.0156766877476755, 1.0164228671351236, 1.0139985511092364, 1.0150528836143955, 1.0157342187742175, 1.0153886992897612, 1.0146531167378112, 1.0157080710577713, 1.0158648886698802, 1.0182284827907908, 1.0152995720260938, 1.0152995720260938, 1.015990224227692, 1.0165217298878426, 1.0150003439807975, 1.015943235725438, 1.0156766877476755, 1.015283838152071, 1.0155091984894753, 1.0161936703612284, 1.0177752466882426, 1.0161780304952206, 1.0171549802098723, 1.0209650231813387, 1.017299938994153, 1.01515790732731, 1.0163187303709083, 1.0186290733713, 1.0141096078225886, 1.0162353686658412, 1.0155301449356549, 1.0140937476570744, 1.015786500464173, 1.0168750197310084, 1.0142047332993018, 1.0156086679179377, 1.0170513522059572, 1.0160528525670043, 1.0146109735015392, 1.0154149030532622, 1.0158335383284438, 1.0187572419457929, 1.0171860546252962, 1.0149635552078113, 1.0168075435249222, 1.0193811410544047, 1.015147408286714, 1.0150843985024522, 1.0162770553332052, 1.0150738942804902, 1.0152995720260938, 1.0177958780775718, 1.0162301570143324, 1.0155615590896958, 1.0161884572545297, 1.018557251163877, 1.0158648886698802, 1.0152261330662518, 1.0150423771700186, 1.0164905171357372, 1.0143842488889845, 1.016000664108858, 1.0150476304848304, 1.014468651901877, 1.0153153042394674, 1.0162718451359374, 1.0145424652790085, 1.0149267573457414, 1.0157655899864004, 1.016240580135518, 1.0150266161139476, 1.0153310347926006, 1.0158439891740134, 1.016240580135518, 1.016073722843569, 1.0154882491007136, 1.0161623889912554, 1.0193658302785937, 1.0146478494858298, 1.0146267786136223, 1.0153624909197847, 1.0146899822834188, 1.0147005136196128, 1.0152313799064865, 1.0166828920294275, 1.0153729748206732, 1.0160267606182638, 1.0191053083352477, 1.0160945902034528, 1.014937271948382, 1.0145424652790085, 1.0171290799348067, 1.0139297601049175, 1.0151946481449985, 1.0153729748206732, 1.0141307520780787, 1.0145266512091153, 1.0155353810875347, 1.0136542771308117, 1.0138874113450633, 1.0152576113372542, 1.0153572486928457, 1.0142047332993018, 1.0153205479416294, 1.0148952090829633, 1.0173568487110334, 1.0158596640702853, 1.0154568194981166, 1.0151054047248156, 1.0189518489981624, 1.014479198912304, 1.0157185306942622, 1.0179865839498088, 1.016755618028272, 1.017687531587005, 1.0181924800159017, 1.0193300990735388, 1.0175636110319408, 1.0185213271736282, 1.020002463323265, 1.0176462361212903, 1.0160998065878042, 1.016073722843569, 1.0180638280994365, 1.014984578476416, 1.0166049320426864, 1.0163760145726164, 1.0147373674299507, 1.0163812211384273, 1.0169943262018561, 1.0147899999089038, 1.0160945902034528, 1.0171653390651394, 1.017418907382365, 1.0152261330662518, 1.0162822653487598, 1.017160159727117, 1.018767490708871, 1.0179968854687504, 1.0160580704096362, 1.0170565353106946, 1.0199973809249756, 1.0156243675548937, 1.0161258857765854, 1.0170513522059572, 1.0156034343383893, 1.0157603619090596, 1.0162666347569413, 1.0169632119459033, 1.0163760145726164, 1.0173051134986473, 1.0194066555517514, 1.0172378309872285, 1.0150003439807975, 1.0160841568880365, 1.0175894362672697, 1.0135322657126848, 1.0151106558176701, 1.0153310347926006, 1.0141466082963462, 1.017206767319056, 1.0173361567709598, 1.01373909555159, 1.0159850040133198, 1.017873220507974, 1.0165217298878426, 1.0146636506825977, 1.0156034343383893, 1.0159484574005953, 1.01820791083444, 1.0165841358451435, 1.0151054047248156, 1.0168594510003388, 1.0187316169785994, 1.0154987241629776, 1.0151054047248156, 1.0156766877476755, 1.0152156388315794, 1.0152995720260938, 1.015995444259533, 1.0159066788838742, 1.0153624909197847, 1.016136316176987, 1.0194372672378234, 1.016615329056695, 1.0151841516928464, 1.0144475556376435, 1.0176617232545466, 1.0142152990407602, 1.0150423771700186, 1.0157185306942622, 1.0143736951443285, 1.0154044221005176, 1.016000664108858, 1.0141413230781637, 1.0147321031584786, 1.0160841568880365, 1.0154358627486721, 1.014468651901877, 1.0156243675548937, 1.015289082961287, 1.0171498005133908, 1.0163291473140879, 1.0151316583386012, 1.0155039614181895, 1.0184083672108353, 1.0147899999089038, 1.016068505547904, 1.0155353810875347, 1.0153677329623887, 1.0156609936165335, 1.0156923802279527, 1.0152628570694329, 1.015958900202973, 1.0157446765778417, 1.018146178035371, 1.015922347198008, 1.0151316583386012, 1.0155039614181895, 1.017315461971199, 1.0147531591275227, 1.017299938994153, 1.015352006281557, 1.0141677472903703, 1.0153310347926006, 1.015870113086586, 1.0144475556376435, 1.0149109840497528, 1.015566794138786, 1.0156505299450918, 1.014763685995354, 1.0154725351274918, 1.0158387638427107, 1.0168127350831782, 1.0162510025294351, 1.015136908506288, 1.0153729748206732, 1.017418907382365, 1.0140250007113703, 1.0143420294166567, 1.0150528836143955, 1.0147005136196128, 1.0147742121188887, 1.0175481137536937, 1.015136908506288, 1.0149477858087508, 1.0155301449356549, 1.0181564685994193, 1.015524908599924, 1.014984578476416, 1.0144000781021125, 1.0164488899903472, 1.0138979996666315, 1.0157708178805673, 1.0147268387008401, 1.0140673102868314, 1.0147373674299507, 1.0153415209058696, 1.0138503462761768, 1.0142997979564818, 1.0155824981836445, 1.015556323856845, 1.0145266512091153, 1.0154830112936315, 1.0157394477676542, 1.0166932836236608, 1.0159014557469765, 1.0152366265620072, 1.0152313799064865, 1.0172533604045513, 1.0140197111674973, 1.0140091315149518, 1.0165841358451435, 1.0157237602375366, 1.0161206703031762, 1.0181153021071017, 1.0183364393143477, 1.0165633367541163, 1.017170518223954, 1.0199770496169196, 1.0169735840834968, 1.0158805613713882, 1.0165477355364303, 1.017708175053331, 1.0155091984894753, 1.0171549802098723, 1.0158544392877857, 1.015273347979937, 1.0161571747925409, 1.0174395878929214, 1.0148952090829633, 1.0158753373204168, 1.0163968397474141, 1.015938013867616, 1.015786500464173, 1.0158753373204168, 1.0165529361232517, 1.017831976177511, 1.01604763454202, 1.0159275696039156, 1.0171394405826593, 1.01720158941429, 1.0158335383284438, 1.0153310347926006, 1.0149057259131546, 1.0143314726757844, 1.0144264563814116, 1.015289082961287, 1.0156923802279527, 1.0150476304848304, 1.0156296004000327, 1.0187111138570109, 1.0157708178805673, 1.0146267786136223, 1.0147531591275227, 1.0165529361232517, 1.0145530070586377, 1.0165737366613743, 1.0146689173754333, 1.0138556418521814, 1.0149320147398535, 1.0155406170555783, 1.0140990345669338, 1.0145371941091195, 1.015572029004131, 1.0150686418917607, 1.0141096078225886, 1.0153991813478327, 1.015115906725461, 1.0169165284262118, 1.0158074080121189, 1.0149057259131546, 1.0149740672130354, 1.0162822653487598, 1.013686089715512, 1.0136277614366898, 1.0159745630369232, 1.0152261330662518, 1.0163916337258116, 1.0176462361212903, 1.01995163162231, 1.0164072512465143, 1.0176772087873809, 1.0189672019842715, 1.0169320912180686, 1.0153939404109187, 1.015697610687923, 1.0183313002881842, 1.0144211810997374, 1.0158178606877064, 1.0153362779414403, 1.014558277668409, 1.0151894000113402, 1.0154096626689892, 1.0141043212887666, 1.0151211574482026, 1.018084419822265, 1.0195749428074887, 1.015289082961287, 1.0160424163346686, 1.0190644011613705, 1.0205351635545368, 1.0201345455348545, 1.017170518223954, 1.0164697050123757, 1.0196411861507386, 1.0148952090829633, 1.0149425289713427, 1.015566794138786, 1.0150581365587286, 1.0153782164946534, 1.0158753373204168, 1.0160424163346686, 1.0157917276257933, 1.0163656008966826, 1.019258611188973, 1.0153782164946534, 1.0152576113372542, 1.0159850040133198, 1.0146899822834188, 1.013686089715512, 1.0144581041436982, 1.014225864031485, 1.014114894168415, 1.0157133009676789, 1.0163395635310057, 1.0138715274477732, 1.015462058225284, 1.0153310347926006, 1.0152418730328292, 1.0145213794789691, 1.015451580586887, 1.015524908599924, 1.0171342603483804, 1.0149057259131546, 1.0146320466113472, 1.0166517129127266, 1.0157603619090596, 1.0147321031584786, 1.0136807880912824, 1.0166776959614723, 1.0160111032600192, 1.0160267606182638, 1.0165633367541163, 1.0172740637889197, 1.0169839555021092, 1.017030617991591, 1.0200329541127529, 1.0163031035941392, 1.0156452978341215, 1.0164853143765953, 1.015917124609375, 1.0148583943272382, 1.016240580135518, 1.0169372784556108, 1.0151001534468818, 1.0167400368629493, 1.0171860546252962, 1.0149740672130354, 1.015870113086586, 1.0160215416812954, 1.0158544392877857, 1.0153834579843444, 1.0158230867509566, 1.015917124609375, 1.018290181742486, 1.0157655899864004, 1.0154044221005176, 1.017144620637658, 1.0171394405826593, 1.0161154546476083, 1.017108356487274, 1.0160163225618857, 1.014984578476416, 1.0155406170555783, 1.0156400655396314, 1.0161676030079305, 1.0159484574005953, 1.0162353686658412, 1.0190592869818669, 1.0153205479416294, 1.014800524172235, 1.0159536788931018, 1.0142469917612325, 1.0135110360967017, 1.014157178169068, 1.013717895487165, 1.0135641044456811, 1.0157394477676542, 1.0163916337258116, 1.014030290066998, 1.0152785931582926, 1.016256213453705, 1.0151841516928464, 1.01478473749825, 1.0152681026169887, 1.0154882491007136, 1.0170720835478895, 1.0150686418917607, 1.0146057047578239, 1.0166101306400754, 1.0161676030079305, 1.0148426137881246, 1.0139297601049175, 1.015462058225284, 1.014984578476416, 1.0151946481449985, 1.0184032306468849, 1.0159484574005953, 1.0154411022121796, 1.0159327918271133, 1.018880180983575, 1.0155301449356549, 1.0149793229374486, 1.0155772636857454, 1.0162510025294351, 1.0138715274477732, 1.0151789031895015, 1.0142100162638803, 1.013972096799008, 1.0154830112936315, 1.0161571747925409, 1.0139509299596814, 1.0147794749015833, 1.0156400655396314, 1.0153153042394674, 1.0142311462453613, 1.0153782164946534, 1.015289082961287, 1.0163499790217805, 1.0149635552078113, 1.014695248044653, 1.0160893736368688, 1.0160111032600192, 1.0145371941091195, 1.0142945181806682, 1.0156609936165335, 1.014874173194172, 1.0153624909197847, 1.0190337134741503, 1.0173568487110334, 1.0158596640702853, 1.0162770553332052, 1.0206111101795539, 1.016204096028789, 1.0144053541321891, 1.0153572486928457, 1.0175739416602632, 1.013585326475171, 1.0145530070586377, 1.015115906725461, 1.0134844948067068, 1.0154253832692735, 1.0162301570143324, 1.0144581041436982, 1.0150843985024522, 1.0164801114363309, 1.0157394477676542, 1.0148110476917, 1.0155929666283572, 1.0155039614181895, 1.0167608113893092, 1.0155039614181895, 1.0148110476917, 1.0162666347569413, 1.017532614872185, 1.0146109735015392, 1.0148320924995218, 1.0170720835478895, 1.0159641213302237, 1.0160163225618857, 1.018880180983575, 1.0179144534951419, 1.0163083127013486, 1.017113537618172, 1.019875351891963, 1.0167452307651066, 1.015430623101042, 1.0166932836236608, 1.0167763903904161, 1.0153467636859035, 1.0161936703612284, 1.014984578476416, 1.014874173194172, 1.0161154546476083, 1.0174809403497347, 1.0145319227524936, 1.0158335383284438, 1.0157917276257933, 1.0158439891740134, 1.0150476304848304, 1.0158230867509566, 1.0164280720687082, 1.017770088397171, 1.0158492143223667, 1.015147408286714, 1.0173309833391513, 1.017615257051966, 1.0156557618725575, 1.0143525854082889, 1.0162197331657594, 1.0157603619090596, 1.0159693422748688, 1.0187982328036718, 1.017170518223954, 1.0164488899903472, 1.0166309232220854, 1.0192279631189893, 1.0162978943052905, 1.0153782164946534, 1.016755618028272, 1.016714064645832, 1.0152943275859563, 1.017367193608976, 1.0151998960938364, 1.0143684179911827, 1.0161884572545297, 1.0169113404691343, 1.0147689491501508, 1.0158230867509566, 1.0159641213302237, 1.0158178606877064, 1.0150843985024522, 1.0157917276257933, 1.016000664108858, 1.0177288156765236, 1.0156557618725575, 1.0152523654204375, 1.0166465157610807, 1.0165945343055418, 1.0151106558176701, 1.0138768222688825]\n"
     ]
    }
   ],
   "source": [
    "print(pfd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(labels, class_label):\n",
    "    em_labels = []\n",
    "    if(class_label == 'valence'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                em_labels.append(1)\n",
    "            else: # low valence\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'arousal'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][1]>5): # high arousal\n",
    "                em_labels.append(1)\n",
    "            else: # low arousal\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'all'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(1) # HVHA\n",
    "                else:\n",
    "                    em_labels.append(0) # HVLA\n",
    "            else: # low valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(2) # LVHA\n",
    "                else: # low arousal\n",
    "                    em_labels.append(3) # LVLA\n",
    "        return em_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pfd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pfd_m2 = np.array(pfd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pfd_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "print(pfd_m2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0154149  1.01521039 1.01533628 ... 1.01659453 1.01511066 1.01387682]\n"
     ]
    }
   ],
   "source": [
    "print(pfd_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "print(pfd_m2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680\n"
     ]
    }
   ],
   "source": [
    "from eeglib.helpers import CSVHelper\n",
    "\n",
    "helper= CSVHelper(\"D:/Brain Computer interface/f1.csv\")\n",
    "\n",
    "for eeg in helper:\n",
    "    print(eeg.PFD().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.05886994 1.0521725  1.0521725  ... 1.05886994 1.05886994 1.04880306]\n"
     ]
    }
   ],
   "source": [
    "print(eeg.PFD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eeg.PFD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfd = np.array(eeg.PFD())\n",
    "pfd = np.reshape(eeg.PFD(), (-1, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 32)\n"
     ]
    }
   ],
   "source": [
    "print(pfd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(labels, class_label):\n",
    "    em_labels = []\n",
    "    if(class_label == 'valence'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                em_labels.append(1)\n",
    "            else: # low valence\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'arousal'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][1]>5): # high arousal\n",
    "                em_labels.append(1)\n",
    "            else: # low arousal\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'all'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(1) # HVHA\n",
    "                else:\n",
    "                    em_labels.append(0) # HVLA\n",
    "            else: # low valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(2) # LVHA\n",
    "                else: # low arousal\n",
    "                    em_labels.append(3) # LVLA\n",
    "        return em_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_label = emotion_label(labels, \"valence\")\n",
    "y1 = []\n",
    "for i in range(len(valence_label)):\n",
    "    for j in range(6):\n",
    "        y1.append(valence_label[i])\n",
    "y1 = np.array(y1)\n",
    "valence_label = y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predictf = clf.predict(X_test)\n",
    "print (y_predictf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#performane evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_predictf)\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(valence_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name2 = []\n",
    "for i in range(32):\n",
    "    columns_name2.append('ch' + str(i))\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame(pfd, columns = columns_name2)\n",
    "\n",
    "\n",
    "tot_features = len(df3.columns)-1\n",
    "total_features = tot_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(total_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_label = emotion_label(labels, \"valence\")\n",
    "\n",
    "X = df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ch0       ch1       ch2       ch3       ch4       ch5       ch6  \\\n",
      "0    1.058870  1.052173  1.052173  1.048803  1.058870  1.058870  1.068816   \n",
      "1    1.062198  1.062198  1.052173  1.055528  1.055528  1.062198  1.062198   \n",
      "2    1.078649  1.068816  1.062198  1.065514  1.062198  1.055528  1.068816   \n",
      "3    1.065514  1.052173  1.062198  1.068816  1.065514  1.072106  1.058870   \n",
      "4    1.058870  1.058870  1.058870  1.058870  1.068816  1.068816  1.062198   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "235  1.055528  1.062198  1.068816  1.055528  1.045419  1.065514  1.062198   \n",
      "236  1.058870  1.045419  1.065514  1.065514  1.072106  1.055528  1.055528   \n",
      "237  1.062198  1.068816  1.078649  1.058870  1.065514  1.065514  1.062198   \n",
      "238  1.055528  1.058870  1.062198  1.058870  1.062198  1.065514  1.052173   \n",
      "239  1.075384  1.055528  1.058870  1.068816  1.052173  1.078649  1.075384   \n",
      "\n",
      "          ch7       ch8       ch9  ...      ch22      ch23      ch24  \\\n",
      "0    1.075384  1.075384  1.062198  ...  1.058870  1.062198  1.058870   \n",
      "1    1.052173  1.062198  1.062198  ...  1.055528  1.062198  1.072106   \n",
      "2    1.065514  1.048803  1.048803  ...  1.058870  1.058870  1.062198   \n",
      "3    1.055528  1.062198  1.068816  ...  1.058870  1.075384  1.075384   \n",
      "4    1.062198  1.062198  1.055528  ...  1.052173  1.058870  1.065514   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "235  1.062198  1.048803  1.055528  ...  1.052173  1.058870  1.062198   \n",
      "236  1.058870  1.075384  1.068816  ...  1.058870  1.045419  1.048803   \n",
      "237  1.068816  1.062198  1.055528  ...  1.048803  1.055528  1.052173   \n",
      "238  1.058870  1.065514  1.065514  ...  1.068816  1.072106  1.062198   \n",
      "239  1.065514  1.062198  1.052173  ...  1.062198  1.055528  1.058870   \n",
      "\n",
      "         ch25      ch26      ch27      ch28      ch29      ch30      ch31  \n",
      "0    1.055528  1.062198  1.048803  1.048803  1.055528  1.062198  1.052173  \n",
      "1    1.052173  1.042021  1.055528  1.072106  1.058870  1.058870  1.062198  \n",
      "2    1.048803  1.058870  1.055528  1.072106  1.058870  1.068816  1.055528  \n",
      "3    1.062198  1.055528  1.058870  1.081903  1.075384  1.062198  1.052173  \n",
      "4    1.065514  1.072106  1.065514  1.072106  1.052173  1.058870  1.055528  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "235  1.062198  1.062198  1.075384  1.062198  1.075384  1.065514  1.075384  \n",
      "236  1.065514  1.058870  1.065514  1.072106  1.065514  1.055528  1.052173  \n",
      "237  1.062198  1.062198  1.048803  1.065514  1.058870  1.062198  1.055528  \n",
      "238  1.055528  1.052173  1.058870  1.068816  1.055528  1.048803  1.062198  \n",
      "239  1.052173  1.065514  1.058870  1.058870  1.058870  1.058870  1.048803  \n",
      "\n",
      "[240 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ch0       ch1       ch2       ch3       ch4       ch5       ch6  \\\n",
      "0    1.058870  1.052173  1.052173  1.048803  1.058870  1.058870  1.068816   \n",
      "1    1.062198  1.062198  1.052173  1.055528  1.055528  1.062198  1.062198   \n",
      "2    1.078649  1.068816  1.062198  1.065514  1.062198  1.055528  1.068816   \n",
      "3    1.065514  1.052173  1.062198  1.068816  1.065514  1.072106  1.058870   \n",
      "4    1.058870  1.058870  1.058870  1.058870  1.068816  1.068816  1.062198   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "235  1.055528  1.062198  1.068816  1.055528  1.045419  1.065514  1.062198   \n",
      "236  1.058870  1.045419  1.065514  1.065514  1.072106  1.055528  1.055528   \n",
      "237  1.062198  1.068816  1.078649  1.058870  1.065514  1.065514  1.062198   \n",
      "238  1.055528  1.058870  1.062198  1.058870  1.062198  1.065514  1.052173   \n",
      "239  1.075384  1.055528  1.058870  1.068816  1.052173  1.078649  1.075384   \n",
      "\n",
      "          ch7       ch8       ch9  ...      ch22      ch23      ch24  \\\n",
      "0    1.075384  1.075384  1.062198  ...  1.058870  1.062198  1.058870   \n",
      "1    1.052173  1.062198  1.062198  ...  1.055528  1.062198  1.072106   \n",
      "2    1.065514  1.048803  1.048803  ...  1.058870  1.058870  1.062198   \n",
      "3    1.055528  1.062198  1.068816  ...  1.058870  1.075384  1.075384   \n",
      "4    1.062198  1.062198  1.055528  ...  1.052173  1.058870  1.065514   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "235  1.062198  1.048803  1.055528  ...  1.052173  1.058870  1.062198   \n",
      "236  1.058870  1.075384  1.068816  ...  1.058870  1.045419  1.048803   \n",
      "237  1.068816  1.062198  1.055528  ...  1.048803  1.055528  1.052173   \n",
      "238  1.058870  1.065514  1.065514  ...  1.068816  1.072106  1.062198   \n",
      "239  1.065514  1.062198  1.052173  ...  1.062198  1.055528  1.058870   \n",
      "\n",
      "         ch25      ch26      ch27      ch28      ch29      ch30      ch31  \n",
      "0    1.055528  1.062198  1.048803  1.048803  1.055528  1.062198  1.052173  \n",
      "1    1.052173  1.042021  1.055528  1.072106  1.058870  1.058870  1.062198  \n",
      "2    1.048803  1.058870  1.055528  1.072106  1.058870  1.068816  1.055528  \n",
      "3    1.062198  1.055528  1.058870  1.081903  1.075384  1.062198  1.052173  \n",
      "4    1.065514  1.072106  1.065514  1.072106  1.052173  1.058870  1.055528  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "235  1.062198  1.062198  1.075384  1.062198  1.075384  1.065514  1.075384  \n",
      "236  1.065514  1.058870  1.065514  1.072106  1.065514  1.055528  1.052173  \n",
      "237  1.062198  1.062198  1.048803  1.065514  1.058870  1.062198  1.055528  \n",
      "238  1.055528  1.052173  1.058870  1.068816  1.055528  1.048803  1.062198  \n",
      "239  1.052173  1.065514  1.058870  1.058870  1.058870  1.058870  1.048803  \n",
      "\n",
      "[240 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingX=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainingX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfeature.function.similarity_based import fisher_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = fisher_score.fisher_score(trainingX,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 17 27 16  7 22 26 12 25 19  8 11 15  9 18 28  4 13  2  6  1 24 10 30\n",
      " 20  0  3 31 14 29 21 23]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = fisher_score.fisher_score(trainingX, y_train, mode='rank') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 17 27 16  7 22 26 12 25 19  8 11 15  9 18 28  4 13  2  6  1 24 10 30\n",
      " 20  0  3 31 14 29 21 23]\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0521725  1.06219846 1.0521725  ... 1.06219846 1.0521725  1.05552804]\n",
      " [1.05552804 1.06219846 1.05886994 ... 1.06551387 1.05886994 1.0521725 ]\n",
      " [1.05552804 1.06551387 1.07538381 ... 1.06551387 1.04202136 1.06551387]\n",
      " ...\n",
      " [1.06881641 1.06219846 1.05552804 ... 1.06219846 1.06219846 1.07210631]\n",
      " [1.06219846 1.07210631 1.06881641 ... 1.06551387 1.0521725  1.0521725 ]\n",
      " [1.0521725  1.06551387 1.06551387 ... 1.06551387 1.04880306 1.05886994]]\n"
     ]
    }
   ],
   "source": [
    "num_fea = 32\n",
    "\n",
    "\n",
    "\t\t     \n",
    "selected_features_train = trainingX[:, idx[0:num_fea]]\n",
    "\n",
    "\n",
    "\t\t     \n",
    "selected_features_test = testX[:, idx[0:num_fea]]\n",
    "\n",
    "\n",
    "\t\t     \n",
    "print (selected_features_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 32)\n"
     ]
    }
   ],
   "source": [
    "print (selected_features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 32)\n"
     ]
    }
   ],
   "source": [
    "print (selected_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.06881641 1.04880306 1.05552804 ... 1.06219846 1.04541944 1.0521725 ]\n",
      " [1.06551387 1.06881641 1.06551387 ... 1.07864915 1.06881641 1.06219846]\n",
      " [1.06881641 1.06219846 1.05886994 ... 1.05552804 1.05552804 1.06551387]\n",
      " ...\n",
      " [1.05552804 1.05886994 1.04541944 ... 1.05552804 1.05552804 1.06219846]\n",
      " [1.05552804 1.06881641 1.04880306 ... 1.07538381 1.06219846 1.06551387]\n",
      " [1.06881641 1.05886994 1.0521725  ... 1.0521725  1.06219846 1.06551387]]\n"
     ]
    }
   ],
   "source": [
    "print (selected_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(selected_features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(selected_features_test)\n",
    "print (y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#performane evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "print (acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainingX, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predict2 = clf.predict(testX)\n",
    "print (y_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#performane evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_predict2)\n",
    "print (acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(selected_features_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.011349220735993487"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " adjusted_mutual_info_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.576090381163006"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(pfd,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.896320038092677"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(trainingX, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mayfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\namrata\\anaconda3\\lib\\site-packages (1.22.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\namrata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.22.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\namrata\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (1.22.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (2021.5.30)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: ReliefF in c:\\users\\namrata\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from ReliefF) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from ReliefF) (1.22.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from ReliefF) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->ReliefF) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\namrata\\anaconda3\\lib\\site-packages (from scikit-learn->ReliefF) (0.17.0)\n",
      "Requirement already up-to-date: Py_FS in c:\\users\\namrata\\anaconda3\\lib\\site-packages (0.0.44)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install ReliefF\n",
    "!pip install -U Py_FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for the classification accuracy [0-1]: 0\n",
      "Enter the percentage of data wanted for valdiation [0, 100]: 20\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 1\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.59375\n",
      "Number of Features: 13\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 2 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 3 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 4 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 5 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 6 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 7 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 8 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 9 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 10 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 11 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 12 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 13 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 14 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 15 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 16 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 17 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 18 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 19 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 20 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 21 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 22 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 23 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 24 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 25 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 26 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 27 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 28 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 29 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 2\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.53125\n",
      "Number of Features: 15\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 2 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 3 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 4 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 5 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 6 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 7 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 8 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 9 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 10 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 11 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 12 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 13 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 14 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 15 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 16 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 17 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 18 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 19 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 20 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 21 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 22 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 23 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 24 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 25 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 26 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 27 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 28 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 29 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 30 - Fitness: 0.3125, Number of Features: 22\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 3\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.625\n",
      "Number of Features: 12\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.625, Number of Features: 12\n",
      "Mayfly 2 - Fitness: 0.625, Number of Features: 12\n",
      "Mayfly 3 - Fitness: 0.625, Number of Features: 12\n",
      "Mayfly 4 - Fitness: 0.625, Number of Features: 12\n",
      "Mayfly 5 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 6 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 7 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 8 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 9 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 10 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 11 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 12 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 13 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 14 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 15 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 16 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 17 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 18 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 19 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 20 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 21 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 22 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 23 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 24 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 25 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 26 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 27 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 28 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 29 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 30 - Fitness: 0.3125, Number of Features: 22\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 4\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.5625\n",
      "Number of Features: 14\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 2 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 3 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 4 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 5 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 6 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 7 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 8 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 9 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 10 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 11 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 12 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 13 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 14 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 15 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 16 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 17 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 18 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 19 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 20 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 21 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 22 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 23 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 24 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 25 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 26 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 27 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 28 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 29 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.53125\n",
      "Number of Features: 15\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 2 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 3 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 4 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 5 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 6 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 7 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 8 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 9 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 10 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 11 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 12 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 13 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 14 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 15 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 16 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 17 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 18 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 19 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 20 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 21 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 22 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 23 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 24 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 25 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 26 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 27 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 28 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 29 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 6\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.5625\n",
      "Number of Features: 14\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 2 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 3 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 4 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 5 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 6 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 7 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 8 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 9 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 10 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 11 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 12 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 13 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 14 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 15 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 16 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 17 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 18 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 19 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 20 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 21 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 22 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 23 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 24 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 25 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 26 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 27 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 28 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 29 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 7\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.59375\n",
      "Number of Features: 13\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 2 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 3 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 4 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 5 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 6 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 7 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 8 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 9 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 10 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 11 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 12 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 13 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 14 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 15 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 16 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 17 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 18 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 19 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 20 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 21 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 22 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 23 - Fitness: 0.4375, Number of Features: 18\n",
      "Mayfly 24 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 25 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 26 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 27 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 28 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 29 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 8\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.59375\n",
      "Number of Features: 13\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 2 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 3 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 4 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 5 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 6 - Fitness: 0.59375, Number of Features: 13\n",
      "Mayfly 7 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 8 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 9 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 10 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 11 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 12 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 13 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 14 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 15 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 16 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 17 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 18 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 19 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 20 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 21 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 22 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 23 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 24 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 25 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 26 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 27 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 28 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 29 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 30 - Fitness: 0.34375, Number of Features: 21\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 9\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.5625\n",
      "Number of Features: 14\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 2 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 3 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 4 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 5 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 6 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 7 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 8 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 9 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 10 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 11 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 12 - Fitness: 0.5625, Number of Features: 14\n",
      "Mayfly 13 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 14 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 15 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 16 - Fitness: 0.53125, Number of Features: 15\n",
      "Mayfly 17 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 18 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 19 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 20 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 21 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 22 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 23 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 24 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 25 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 26 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 27 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 28 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 29 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 30 - Fitness: 0.3125, Number of Features: 22\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                          Iteration - 10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of agents: 30\n",
      "\n",
      "------------- Best Agent ---------------\n",
      "Fitness: 0.5\n",
      "Number of Features: 16\n",
      "----------------------------------------\n",
      "\n",
      "Mayfly 1 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 2 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 3 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 4 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 5 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 6 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 7 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 8 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 9 - Fitness: 0.5, Number of Features: 16\n",
      "Mayfly 10 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 11 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 12 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 13 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 14 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 15 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 16 - Fitness: 0.46875, Number of Features: 17\n",
      "Mayfly 17 - Fitness: 0.40625, Number of Features: 19\n",
      "Mayfly 18 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 19 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 20 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 21 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 22 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 23 - Fitness: 0.375, Number of Features: 20\n",
      "Mayfly 24 - Fitness: 0.34375, Number of Features: 21\n",
      "Mayfly 25 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 26 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 27 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 28 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 29 - Fitness: 0.3125, Number of Features: 22\n",
      "Mayfly 30 - Fitness: 0.3125, Number of Features: 22\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                                    Final Result                                  \n",
      "================================================================================\n",
      "\n",
      "Leader Mayfly Dimension : 21\n",
      "Leader Mayfly Fitness : 0.71875\n",
      "Leader Mayfly Classification Accuracy : 0.4166666666666667\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Py_FS.wrapper.nature_inspired.MA import MA as FS\n",
    "solution = FS(num_agents=30, max_iter=10, train_data=X, train_label=y1, save_conv_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.best_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.best_agent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4166666666666667"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y1, stratify=y1, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = train_X.to_numpy()\n",
    "CD =test_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\namrata\\anaconda3\\lib\\site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from Py_FS.evaluation.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(len(np.unique(test_Y))) == 2:\n",
    "  # if it is binary classification, you will get a precision, recall and f1_score for each of the labels\n",
    "  result = evaluate(AB, CD, y_train, y_test, agent=solution.best_agent, classifier='knn', save_conf_mat=True)\n",
    "else:  \n",
    "  # for a multi-class problem, you will get a avreaged precision, recall and f1_score\n",
    "  # Options for averaging:\n",
    "  # 1. macro\n",
    "  # 2. weighted\n",
    "  # 3. samples\n",
    "  result = evaluate(AB, CD, y_train, y_test,agent=solution.best_agent, classifier='knn', save_conf_mat=True, averaging=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y1, test_size=0.2, random_state=109)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(train_X, train_Y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfeature.utility import construct_W\n",
    "\n",
    "\n",
    "\t\t     \n",
    "kwargs_W = {\"metric\":\"euclidean\",\"neighbor_mode\":\"knn\",\"weight_mode\":\"heat_kernel\",\"k\":5,'t':1}\n",
    "\n",
    "\n",
    "\t\t     \n",
    "W = construct_W.construct_W(A, **kwargs_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\NAMRATA\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1d3d4a900d32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlap_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlap_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "from skfeature.function.similarity_based import lap_score\n",
    "\n",
    "\n",
    "\t\t     \n",
    "score = lap_score.lap_score(A, W=W)\n",
    "\n",
    "\n",
    "\t\t     \n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lap_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-40bd3896aa99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlap_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlap_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rank'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lap_score' is not defined"
     ]
    }
   ],
   "source": [
    "idx = lap_score.lap_score(A,W=W,mode='rank' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5af36227ea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af817d011a26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_fea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_fea\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "num_fea = 3\n",
    "\n",
    "selected_features = A[:, idx[0:num_fea]]\n",
    "print(selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-ac728b81fd3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mnmi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munsupervised_evaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_selected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_cluster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "from skfeature.utility import unsupervised_evaluation\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "num_cluster = len(np.unique(y1))\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "print (num_cluster)\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "nmi,acc=unsupervised_evaluation.evaluation(X_selected=selected_features,n_clusters=num_cluster,y1=y)\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "print (nmi)\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "print (acc)\n",
    "\n",
    "\n",
    "\t\t\t \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
